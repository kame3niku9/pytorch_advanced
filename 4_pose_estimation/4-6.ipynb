{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaderの作成\n",
    "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(rootpath='./data/')\n",
    "\n",
    "train_dataset = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase='train',\n",
    "                                    transform=DataTransform())\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の定義\n",
    "class OpenPoseLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        saved_for_loss: OpenPoseNetの出力list\n",
    "        heatmap_target: [num_batch, 19, 46, 46]\n",
    "        paf_target: [num_batch, 38, 46, 46]\n",
    "        paf_mask: [num_batch, 38, 46, 46]\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        loss: テンソル 損失の値\n",
    "        '''\n",
    "        total_loss = 0\n",
    "        # stageごとに計算\n",
    "        for j in range(6):\n",
    "            #PAFs\n",
    "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "            \n",
    "            # heatmaps\n",
    "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float() * heat_mask\n",
    "            \n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "            \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = OpenPoseLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    net.to(device)\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    num_train_imgs = len(dataloaders_dict['train'].dataset)\n",
    "    batch_size = dataloaders_dict['train'].batch_size\n",
    "    \n",
    "    iteration = 1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "                optimizer.zero_grad()\n",
    "                print(' (train) ')\n",
    "            else:\n",
    "                continue # 今回はvalはスキップ\n",
    "            \n",
    "            for imgs, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                if imgs.size()[0] == 1:\n",
    "                    continue\n",
    "                \n",
    "                imgs = imgs.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # (out6_1, out6_2)は使わないので_ で代替\n",
    "                    _, saved_for_loss = net(imgs)\n",
    "                    \n",
    "                    loss = criterion(saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print(f'iter {iteration} || Loss: {loss.item()/batch_size:.4f} || 10iter: {duration:.4f} sec.')\n",
    "                            t_iter_start = time.time()\n",
    "                            \n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                            \n",
    "        t_epoch_finish = time.time()\n",
    "        print(f'epoch {epoch+1} || epoch_train_loss: {epoch_train_loss/num_train_imgs:.4f} || epoch_val_loss: {0}')\n",
    "        print(f'timer: {t_epoch_finish - t_epoch_start:.4f} sec.')\n",
    "        t_epoch_start = time.time()\n",
    "        \n",
    "    torch.save(net.state_dict(), 'weights/openpose_net_' + str(epoch+1) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " (train) \n",
      "iter 10 || Loss: 0.0035 || 10iter: 11.1171 sec.\n",
      "iter 20 || Loss: 0.0035 || 10iter: 11.1181 sec.\n",
      "iter 30 || Loss: 0.0043 || 10iter: 11.0731 sec.\n",
      "iter 40 || Loss: 0.0034 || 10iter: 11.2403 sec.\n",
      "iter 50 || Loss: 0.0047 || 10iter: 10.9861 sec.\n",
      "iter 60 || Loss: 0.0050 || 10iter: 11.6048 sec.\n",
      "iter 70 || Loss: 0.0036 || 10iter: 10.7852 sec.\n",
      "iter 80 || Loss: 0.0038 || 10iter: 11.0327 sec.\n",
      "iter 90 || Loss: 0.0050 || 10iter: 10.2230 sec.\n",
      "iter 100 || Loss: 0.0038 || 10iter: 11.4267 sec.\n",
      "iter 110 || Loss: 0.0046 || 10iter: 11.6475 sec.\n",
      "iter 120 || Loss: 0.0031 || 10iter: 11.1521 sec.\n",
      "iter 130 || Loss: 0.0046 || 10iter: 10.5557 sec.\n",
      "iter 140 || Loss: 0.0048 || 10iter: 11.4457 sec.\n",
      "iter 150 || Loss: 0.0038 || 10iter: 11.1559 sec.\n",
      "iter 160 || Loss: 0.0049 || 10iter: 10.5505 sec.\n",
      "iter 170 || Loss: 0.0029 || 10iter: 11.1427 sec.\n",
      "iter 180 || Loss: 0.0033 || 10iter: 12.5570 sec.\n",
      "iter 190 || Loss: 0.0032 || 10iter: 10.4932 sec.\n",
      "iter 200 || Loss: 0.0034 || 10iter: 11.0702 sec.\n",
      "iter 210 || Loss: 0.0040 || 10iter: 11.0196 sec.\n",
      "iter 220 || Loss: 0.0030 || 10iter: 11.1416 sec.\n",
      "iter 230 || Loss: 0.0034 || 10iter: 11.7144 sec.\n",
      "iter 240 || Loss: 0.0045 || 10iter: 11.2190 sec.\n",
      "iter 250 || Loss: 0.0030 || 10iter: 10.4482 sec.\n",
      "iter 260 || Loss: 0.0044 || 10iter: 10.5087 sec.\n",
      "iter 270 || Loss: 0.0037 || 10iter: 10.7956 sec.\n",
      "iter 280 || Loss: 0.0050 || 10iter: 10.6925 sec.\n",
      "iter 290 || Loss: 0.0033 || 10iter: 10.7508 sec.\n",
      "iter 300 || Loss: 0.0050 || 10iter: 11.5469 sec.\n",
      "iter 310 || Loss: 0.0040 || 10iter: 11.0101 sec.\n",
      "iter 320 || Loss: 0.0038 || 10iter: 10.0699 sec.\n",
      "iter 330 || Loss: 0.0049 || 10iter: 11.3569 sec.\n",
      "iter 340 || Loss: 0.0031 || 10iter: 12.1242 sec.\n",
      "iter 350 || Loss: 0.0047 || 10iter: 10.4346 sec.\n",
      "iter 360 || Loss: 0.0033 || 10iter: 12.0850 sec.\n",
      "iter 370 || Loss: 0.0030 || 10iter: 12.1000 sec.\n",
      "iter 380 || Loss: 0.0037 || 10iter: 10.7046 sec.\n",
      "iter 390 || Loss: 0.0038 || 10iter: 10.9229 sec.\n",
      "iter 400 || Loss: 0.0039 || 10iter: 10.7075 sec.\n",
      "epoch 1 || epoch_train_loss: 0.0037 || epoch_val_loss: 0\n",
      "timer: 455.4881 sec.\n",
      "Epoch 2/2\n",
      " (train) \n",
      "iter 410 || Loss: 0.0030 || 10iter: 4.6685 sec.\n",
      "iter 420 || Loss: 0.0039 || 10iter: 11.6991 sec.\n",
      "iter 430 || Loss: 0.0028 || 10iter: 10.4629 sec.\n",
      "iter 440 || Loss: 0.0031 || 10iter: 10.4613 sec.\n",
      "iter 450 || Loss: 0.0030 || 10iter: 11.0425 sec.\n",
      "iter 460 || Loss: 0.0043 || 10iter: 11.5292 sec.\n",
      "iter 470 || Loss: 0.0038 || 10iter: 10.2732 sec.\n",
      "iter 480 || Loss: 0.0038 || 10iter: 10.8034 sec.\n",
      "iter 490 || Loss: 0.0029 || 10iter: 13.0406 sec.\n",
      "iter 500 || Loss: 0.0035 || 10iter: 11.2756 sec.\n",
      "iter 510 || Loss: 0.0039 || 10iter: 11.7052 sec.\n",
      "iter 520 || Loss: 0.0040 || 10iter: 11.2892 sec.\n",
      "iter 530 || Loss: 0.0041 || 10iter: 10.6642 sec.\n",
      "iter 540 || Loss: 0.0041 || 10iter: 11.6655 sec.\n",
      "iter 550 || Loss: 0.0034 || 10iter: 10.7612 sec.\n",
      "iter 560 || Loss: 0.0033 || 10iter: 10.8670 sec.\n",
      "iter 570 || Loss: 0.0035 || 10iter: 11.1609 sec.\n",
      "iter 580 || Loss: 0.0030 || 10iter: 10.7920 sec.\n",
      "iter 590 || Loss: 0.0036 || 10iter: 11.6937 sec.\n",
      "iter 600 || Loss: 0.0040 || 10iter: 12.8924 sec.\n",
      "iter 610 || Loss: 0.0041 || 10iter: 11.0408 sec.\n",
      "iter 620 || Loss: 0.0037 || 10iter: 11.1965 sec.\n",
      "iter 630 || Loss: 0.0043 || 10iter: 11.4832 sec.\n",
      "iter 640 || Loss: 0.0032 || 10iter: 11.4407 sec.\n",
      "iter 650 || Loss: 0.0029 || 10iter: 11.3505 sec.\n",
      "iter 660 || Loss: 0.0045 || 10iter: 11.0708 sec.\n",
      "iter 670 || Loss: 0.0036 || 10iter: 11.6096 sec.\n",
      "iter 680 || Loss: 0.0029 || 10iter: 10.7040 sec.\n",
      "iter 690 || Loss: 0.0029 || 10iter: 10.9760 sec.\n",
      "iter 700 || Loss: 0.0022 || 10iter: 10.1964 sec.\n",
      "iter 710 || Loss: 0.0028 || 10iter: 10.2251 sec.\n",
      "iter 720 || Loss: 0.0032 || 10iter: 10.7756 sec.\n",
      "iter 730 || Loss: 0.0029 || 10iter: 11.4696 sec.\n",
      "iter 740 || Loss: 0.0042 || 10iter: 10.4027 sec.\n",
      "iter 750 || Loss: 0.0034 || 10iter: 11.4061 sec.\n",
      "iter 760 || Loss: 0.0036 || 10iter: 11.3100 sec.\n",
      "iter 770 || Loss: 0.0034 || 10iter: 12.1246 sec.\n",
      "iter 780 || Loss: 0.0059 || 10iter: 11.5120 sec.\n",
      "iter 790 || Loss: 0.0034 || 10iter: 10.8637 sec.\n",
      "iter 800 || Loss: 0.0041 || 10iter: 12.0269 sec.\n",
      "iter 810 || Loss: 0.0035 || 10iter: 10.9245 sec.\n",
      "epoch 2 || epoch_train_loss: 0.0038 || epoch_val_loss: 0\n",
      "timer: 460.5465 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new] *",
   "language": "python",
   "name": "conda-env-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
