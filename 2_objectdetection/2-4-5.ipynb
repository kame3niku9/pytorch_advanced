{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product as product\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34層のvgg層を実装\n",
    "def make_vgg():\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    \n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'MC',\n",
    "           512, 512, 512, 'M', 512, 512, 512]\n",
    "    \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'MC':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "            \n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (32): ReLU(inplace)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ドウサカクニン\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8層のextrasを実装\n",
    "def make_extras():\n",
    "    layers = []\n",
    "    in_channels = 1024\n",
    "    \n",
    "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
    "    \n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "    \n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動作確認\n",
    "extras_test = make_extras()\n",
    "extras_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaultboxのoffsetを出力する loc_layers\n",
    "# defaultboxに対するclassの確信度を出力する conf_layers\n",
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    \n",
    "    # source1 (VGG22)\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0] * 4, kernel_size=3, padding=1)] # 4は出力するoffset数\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # source2 (VGG最終)\n",
    "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # source3 (extras2)\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # source4 (extras4)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # source5 (extras6)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # source6 (extras8)\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2Norm層の実装\n",
    "class L2Norm(nn.Module):\n",
    "    def __init__(self, input_channels=512, scale=20):\n",
    "        super(L2Norm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale = scale # 係数weightの初期値として設定する値\n",
    "        self.reset_parameters()\n",
    "        self.eps = 1e-10\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        init.constant_(self.weight, self.scale)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt + self.eps\n",
    "        x = torch.div(x, norm)\n",
    "        \n",
    "        weights = self.weigth.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        out = weights * x\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DefaultBoxの実装\n",
    "# 8732 * 4\n",
    "class DBox(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DBox, self).__init__() # objectが親クラスなのにinit？\n",
    "        \n",
    "        self.image_size = cfg['input_size'] # 画像サイズ 300\n",
    "        self.feature_maps = cfg['feature_maps'] # 各sourceの特徴量マップのサイズ[38, 19, 10, 5, 3, 1]\n",
    "        self.num_priors = len(cfg['feature_maps']) # sourceの個数 6\n",
    "        self.steps = cfg['steps'] # DBoxのピクセルサイズ [8, 16, 32, 64, 100, 300] マップサイズとほぼ反比例\n",
    "        self.min_sizes = cfg['min_sizes'] # 小さい正方形のDBoxのピクセルサイズ [30, 60, ]\n",
    "        self.max_sizes = cfg['max_sizes'] # 大きい正方形のDBoxのピクセルサイズ [60, 111, ]\n",
    "        self.aspect_ratios = cfg['aspect_ratios'] # 長方形のDBoxのアスペクト比\n",
    "        \n",
    "    def make_dbox_list(self):\n",
    "        mean = []\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2): # fまでの数での2pearの組み合わせ\n",
    "                f_k = self.image_size / self.steps[k] # 特徴量の画像サイズ 300 / [8, 16, 32, 64, 100, 300]\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "                \n",
    "                # aspect 1 の小さいDBox\n",
    "                s_k = self.min_sizes[k] / self.image_size\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "                \n",
    "                # aspect 1 の大きいDBox\n",
    "                s_k_prime = sqrt(s_k * (self.max_sizes[k] / self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "                \n",
    "                # その他のアスペクト比のDBox\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "                    \n",
    "        output = torch.Tensor(mean).view(-1, 4) # DBoxをテンソルに変換 torch.Size([8732, 4])\n",
    "        output.clamp_(max=1, min=0) # DBoxが画像の外に出るのを防ぐために、大きさ0-1にする\n",
    "        \n",
    "        return output        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8703</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8706</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8714</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8721</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8723</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8724</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8725</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.790443</td>\n",
       "      <td>0.790443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.961249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     0.013333  0.013333  0.100000  0.100000\n",
       "1     0.013333  0.013333  0.141421  0.141421\n",
       "2     0.013333  0.013333  0.141421  0.070711\n",
       "3     0.013333  0.013333  0.070711  0.141421\n",
       "4     0.040000  0.013333  0.100000  0.100000\n",
       "...        ...       ...       ...       ...\n",
       "8727  0.833333  0.833333  0.502046  1.000000\n",
       "8728  0.500000  0.500000  0.880000  0.880000\n",
       "8729  0.500000  0.500000  0.961249  0.961249\n",
       "8730  0.500000  0.500000  1.000000  0.622254\n",
       "8731  0.500000  0.500000  0.622254  1.000000\n",
       "\n",
       "[8732 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動作の確認\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21, # 背景クラスを含めた合計数\n",
    "    'input_size': 300,\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],\n",
    "    'steps': [8, 16, 32, 64, 100, 300],\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "dbox = DBox(ssd_cfg)\n",
    "dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "pd.DataFrame(dbox_list.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD classを実装\n",
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        \n",
    "        self.phase = phase # train or inference\n",
    "        self.num_classes = cfg['num_classes']\n",
    "        \n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect() #後述\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "ssd_test = SSD(phase='train', cfg=ssd_cfg)\n",
    "print(ssd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5 順伝播関数の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode (DBoxとlocからBBoxを作成)\n",
    "def decode(loc, dbox_list):\n",
    "    \n",
    "    boxes = torch.cat((\n",
    "        dbox_list[:, :2] + loc[:, :2] * 0.1 * dbox_list[:, 2:],\n",
    "        dbox_list[:, 2:] * torch.exp(loc[:, 2:] * 0.2)), dim=1)\n",
    "    # torch.Size([8732, 4])\n",
    "    \n",
    "    # BBoxの座標情報を[cx, cy, width, height]から[xmin, ymin, xmax, ymax]に変換\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2\n",
    "    boxes[:, 2:] += boxes[:, :2]\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Maximum Suppression\n",
    "# もしBBox同士の被っている面積が閾値以上である場合にはconfが一番大きなBBoxのみを残し他は消去。object_classごとに実行\n",
    "def num_suppression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    '''\n",
    "    return. keep: list, count: int\n",
    "    '''\n",
    "    count = 0\n",
    "    keep = scores.new(scores.size(0)).zero().long() # torch.Size([確信度閾値を超えたBBox数])　要素は全部0\n",
    "    \n",
    "    # 各BBoxの面積areaを計算\n",
    "    x1 = bboxes[:, 0]\n",
    "    y1 = bboxes[:, 1]\n",
    "    x2 = bboxes[:, 2]\n",
    "    y2 = bboxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    \n",
    "    # boxesコピー。のちに、BBoxの被り度合いIoUの計算に使用する際の雛形\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "    \n",
    "    # scoreを昇順に並び替え\n",
    "    v, idx = scores.sort(0)\n",
    "    \n",
    "    #上位top_kのBBoxのindexを取り出す\n",
    "    idx = idx[-top_k:]\n",
    "    \n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1] # 現在のconf最大のindexをiに\n",
    "        \n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        \n",
    "        if idx.size(0) == 1: # 最後のBBox\n",
    "            break\n",
    "        \n",
    "        idx = idx[:-1] # idxを一つ減らす\n",
    "        \n",
    "        # ここから、keepに格納したBBoxと被りの大きいBBoxを抽出して除去する\n",
    "        # 一つ減らしたidxまでのBBoxをoutに指定した変数として作成\n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
    "        \n",
    "        # 全てのBBoxに対して、現在のBBox=indexがiと被っている値までに設定\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
    "        \n",
    "        # wとhのテンソルサイズをindexを1つ減らしたものにする\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "\n",
    "        # clampした状態でのBBoxの幅と高さを求める\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "\n",
    "        # 幅や高さが負になっているものは0にする\n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "\n",
    "        # clampされた状態での面積を求める\n",
    "        inter = tmp_w*tmp_h\n",
    "\n",
    "        # IoU = intersect部分 / (area(a) + area(b) - intersect部分)の計算\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # 各BBoxの元の面積\n",
    "        union = (rem_areas - inter) + area[i]  # 2つのエリアのANDの面積\n",
    "        IoU = inter/union\n",
    "\n",
    "        # IoUがoverlapより小さいidxのみを残す\n",
    "        idx = idx[IoU.le(overlap)]  # leはLess than or Equal toの処理をする演算です\n",
    "        # IoUがoverlapより大きいidxは、最初に選んでkeepに格納したidxと同じ物体に対してBBoxを囲んでいるため消去\n",
    "        \n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect実装\n",
    "# 出力テンソル (batch_num, class_num, top_k_num, BBox_info[conf, xmin, ymin, width, height])\n",
    "class Detect(Function):\n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax = nn.Softmax(dim=-1) # confをsoftmaxで正規化するために用意\n",
    "        self.conf_thresh = conf_thresh    # confがthreshより高いDBoxのみ扱う\n",
    "        self.top_k = top_k                # num_supressionでconfの高いtop_k個を計算に使用\n",
    "        self.nms_thresh = nms_thresh\n",
    "        \n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        loc_data: [batch_num, 8732, 4] offset info\n",
    "        conf_data: [batch_num, 8732, num_classes] \n",
    "        dbox_list: [8732, 4] DBox info\n",
    "        \n",
    "        Returns\n",
    "        ------\n",
    "        output: torch.Size([batch_num, 21, 200, 5])\n",
    "        '''\n",
    "        \n",
    "        num_batch = loc_data.size(0) # minibatchのサイズ\n",
    "        num_dbox = loc_data.size(1) # DBoxの数\n",
    "        num_classes = conf_data.size(2) # class num=21\n",
    "        \n",
    "        conf_data = self.softmax(conf_data)\n",
    "        \n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        # conf_dataを[batch_num, 8732, num_classes]から[batch_num, num_classes, 8732]に変更\n",
    "        conf_preds = conf_data.transpose(2, 1)\n",
    "        \n",
    "        # Mini_bacthごとにループ\n",
    "        for i in range(num_batch):\n",
    "            # locとDBoxから修正したBBox[xmin, ymin, xmax, ymax]を求める\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "            \n",
    "            # confのコピーを作成\n",
    "            conf_scores = conf_preds[i].clone()\n",
    "            \n",
    "            # 画像クラスごとのループ\n",
    "            for cl in range(1, num_classes):\n",
    "                # confの閾値を超えたBBoxを取り出す\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh) # gt=greater than\n",
    "                # c_mask: torch.Size([8732])\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "                \n",
    "                if scores.nelement() == 0:\n",
    "                    continue\n",
    "                    \n",
    "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
    "                # l_mask: torch.Size([8732, 4])\n",
    "                \n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                # decoded_boxesで一次元になってしまうので、viewで(閾値を超えたBBox数, 4)に変形\n",
    "                \n",
    "                ids, count = nm_supression(boxes, scores, self.nms_thresh, self.top_k)\n",
    "                \n",
    "                output[i, cl, :count] = torch.cat((socres[ids[:count]].unsqueeze(1), boxes[ids[:count]]), 1)\n",
    "                \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 順伝播を実装し、SSD modelを実装\n",
    "class SSD(nn.Module):\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "        \n",
    "        self.phase = phase\n",
    "        self.num_classes = cfg['num_classes']\n",
    "        \n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        dbox = DBox(self)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        sources = []\n",
    "        loc = []\n",
    "        conf = []\n",
    "        \n",
    "        for k in range(23): # vggのconv4_3まで計算(source1)\n",
    "            x = self.vgg[k](x)\n",
    "        \n",
    "        # conv4_3の出力をL2Normに入力し、source1を作成\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "        \n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        \n",
    "        sources.append(x) #source2\n",
    "        \n",
    "        # extrasのconvとReLUを計算\n",
    "        # source3-6をsourcesに追加\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1: # conv -> ReLU -> conv -> ReLUしてからsourceにいれる\n",
    "                sources.append(x)\n",
    "                \n",
    "        # source1~6に、それぞれ対応する畳み込みを1回ずつ適用する\n",
    "        # zipでforループの複数のリストの要素を取得\n",
    "        # source1-6まであるので6回ループ\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "            # l(x)とc(x)で畳み込みを実行\n",
    "            # l(x)とc(x)の出力サイズは[batch_num, 4*アスペクト比の種類数, featuremapの高さ, featuremap幅]\n",
    "            # sourceによって、アスペクト比の種類数が異なり、面倒なので順番入れ替えて整える\n",
    "            # permuteで要素の順番を入れ替え、\n",
    "            # [minibatch数, featuremap数, featuremap数,4*アスペクト比の種類数]へ\n",
    "            # （注釈）\n",
    "            # torch.contiguous()はメモリ上で要素を連続的に配置し直す命令です。\n",
    "            # あとでview関数を使用します。\n",
    "            # このviewを行うためには、対象の変数がメモリ上で連続配置されている必要があります。\n",
    "        \n",
    "        # locとconfの変形\n",
    "        # loc: torch.Size([batch_num, 34928]), conf: torch.Size([batch_num, 183372])\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
    "            \n",
    "        # さらに変形\n",
    "        # loc: torch.Size([batch_num, 8732, 4]), conf: torch.Size([batch_num, 8732, 21])\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "        \n",
    "        output = (loc, conf, self.dbox_list)\n",
    "        \n",
    "        if self.phase == 'inference':\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "        \n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new]",
   "language": "python",
   "name": "conda-env-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
